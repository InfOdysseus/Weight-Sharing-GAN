{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "from MiddleBlock.DiscriminatorMiddleBlock import DiscriminatorMiddleBlock\n",
    "from MiddleBlock.GeneratorMiddleBlock import GeneratorMiddleBlock\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "from IPython import display\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.models as models\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 100 # 노이즈 벡터의 크기\n",
    "nc = 1 # 채널의 수\n",
    "ngf = 64 # generator 필터 조정\n",
    "ndf = 64 # discriminator 필터 조정\n",
    "niter = 200 # 에폭 수\n",
    "lr = 0.0001\n",
    "beta1 = 0.9\n",
    "\n",
    "imageSize = 64 # 만들어지는 이미지의 크기\n",
    "batchSize = 64 # 미니배치의 크기\n",
    "outf = \"result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.ToTensor()                    \n",
    "])\n",
    "\n",
    "dataset = dsets.MNIST(root='./data/', train=True, download=True, transform=transform)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size= batchSize, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size= batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:         # Conv weight init\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:  # BatchNorm weight init\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netG, self).__init__()\n",
    "        self.firstConv = nn.Conv2d(ndf*4, 10+1, 4,1)\n",
    "        self.randomVec = nn.ConvTranspose2d(nz, ngf*4, 4, 1, 0)\n",
    "        self.catConv = nn.ConvTranspose2d(ngf*4+ngf*4, ngf*4, 4, 2, 1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(ngf, nc, 3, padding = 1)\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            GeneratorMiddleBlock((ndf*4, ndf*4, 4,2,1),(ndf*2, ndf*4, 4,2,1)),\n",
    "            GeneratorMiddleBlock((ndf*2, ndf*4, 4,2,1),(ndf, ndf*2, 4,2,1), batchNorm = True),\n",
    "            GeneratorMiddleBlock((ndf, ndf*2, 4,2,1),(nc, ndf, 4,2,1), batchNorm = True),\n",
    "            GeneratorMiddleBlock((nc, ndf, 4,2,1),last = True, img_channel = 1),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input, label):\n",
    "        first = self.firstConv.weight[label]\n",
    "        \n",
    "        output = torch.cat([F.relu(self.randomVec(input)), first], dim=1)\n",
    "        output = self.catConv(output)\n",
    "        output = self.main(output)\n",
    "        output = torch.tanh(output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netD, self).__init__()\n",
    "        self.labelClassify = nn.Conv2d(ndf*4, 11, 4, 1, 0)\n",
    "        self.main = nn.Sequential(\n",
    "            # (nc) x 64 x 64)\n",
    "            DiscriminatorMiddleBlock(nc, ndf, 4,2,1, dropout_ratio=0.5,batchNorm = True),\n",
    "            # (ndf) x 32 x 32\n",
    "            DiscriminatorMiddleBlock(ndf, ndf*2, 4,2,1, dropout_ratio=0.5, batchNorm = True),\n",
    "            #(ndf*2) x 16 x 16\n",
    "            DiscriminatorMiddleBlock(ndf*2, ndf*4, 4,2,1, dropout_ratio=0.5),\n",
    "            #(ndf*4) x 8 x 8\n",
    "            DiscriminatorMiddleBlock(ndf*4, ndf*4, 4,2,1) #55\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return self.labelClassify(output).view(output.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG(\n",
      "  (firstConv): Conv2d(256, 11, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (randomVec): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (catConv): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (main): Sequential(\n",
      "    (0): GeneratorMiddleBlock(\n",
      "      (branch): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (firstTransposed): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (secondTransposed): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (1): GeneratorMiddleBlock(\n",
      "      (branch): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (firstTransposed): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (secondTransposed): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (2): GeneratorMiddleBlock(\n",
      "      (branch): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (firstTransposed): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (secondTransposed): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (3): GeneratorMiddleBlock(\n",
      "      (branch): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (firstTransposed): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "_netD(\n",
      "  (labelClassify): Conv2d(256, 11, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (main): Sequential(\n",
      "    (0): DiscriminatorMiddleBlock(\n",
      "      (conv): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (1): DiscriminatorMiddleBlock(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (2): DiscriminatorMiddleBlock(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (3): DiscriminatorMiddleBlock(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def copyWeight(netD, netG, tau):\n",
    "    netG.firstConv.load_state_dict(netD.labelClassify.state_dict())\n",
    "    for i, layer in enumerate(netG.main):\n",
    "        layer.conv.load_state_dict(netD.main[len(netD.main) - i - 1].conv.state_dict())\n",
    "        \n",
    "netG = _netG().to(device)\n",
    "netG.apply(weights_init)\n",
    "print(netG)\n",
    "\n",
    "netD = _netD().to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "copyWeight(netD, netG, 0.05)\n",
    "fixed_noise = torch.randn(batchSize, nz, 1, 1, device=device)\n",
    "fixed_noise_label = torch.randint(10, size = (batchSize,), device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lr)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lr)\n",
    "writer = SummaryWriter()\n",
    "total_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n",
      "99 step\n",
      "199 step\n",
      "299 step\n",
      "399 step\n",
      "499 step\n",
      "599 step\n",
      "699 step\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    data = None\n",
    "    #netG.train()\n",
    "    for i, (data,label) in enumerate(train_loader):\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        batch_size = data.shape[0]\n",
    "        label = label.to(device)\n",
    "        output= netD(data.to(device))\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        \n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        \n",
    "        output = netD(netG(noise, label).detach())\n",
    "        fake_labels = torch.ones_like(label)*10\n",
    "        errD_fake = criterion(output, fake_labels)\n",
    "        errD_fake.backward()\n",
    "        errD = errD_real + errD_fake\n",
    "        writer.add_scalar('Discriminator total loss',\n",
    "                                      errD, total_step)\n",
    "        optimizerD.step()\n",
    "        copyWeight(netD, netG,0.05)\n",
    "        \n",
    "        netG.zero_grad()\n",
    "        \n",
    "        fake = netG(noise, label)\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        writer.add_scalar('Generator total loss',\n",
    "                                      errG, total_step)\n",
    "\n",
    "        \n",
    "        sampleNoise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        sampleLoss = F.smooth_l1_loss(netG(sampleNoise,label).detach(),netG(noise, label))\n",
    "        (-torch.log(sampleLoss)).backward()\n",
    "        optimizerG.step()\n",
    "        total_step += 1\n",
    "        if ((i+1) % 100 == 0):\n",
    "            print(i, \"step\")\n",
    "            #print(sampleLoss)\n",
    "            #netG.eval()\n",
    "            fake = netG(fixed_noise, fixed_noise_label)\n",
    "            #netG.train()\n",
    "            vutils.save_image(fake.data,\n",
    "                '%s/fake_samples_epoch_%s.png' % (outf, str(epoch)+\" \"+str(i+1)),\n",
    "                normalize=True)\n",
    "    vutils.save_image(data,\n",
    "            '%s/real_samples.png' % outf,\n",
    "            normalize=True)\n",
    "    fake = netG(fixed_noise,fixed_noise_label) \n",
    "    vutils.save_image(fake.data,\n",
    "            '%s/fake_samples_epoch_%s.png' % (outf, epoch),\n",
    "            normalize=True)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG.pth' % (outf))\n",
    "    torch.save(netD.state_dict(), '%s/netD.pth' % (outf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG.eval()\n",
    "\n",
    "randomLabel = torch.randint(10, size = (batchSize,), device=device) \n",
    "randomLabel.fill_(np.random.randint(10))\n",
    "fake = netG(fixed_noise, randomLabel)\n",
    "netG.train()\n",
    "vutils.save_image(fake.data,\n",
    "                '%s/test_%s.png' % (outf, str(epoch)+\" \"+str(i+1)),\n",
    "                normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
